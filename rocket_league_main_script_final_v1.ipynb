{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhUaD6zCs7mZ"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform\n",
        "!pip install vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvGcI6YqtB0d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from google.colab import drive\n",
        "from vertexai.generative_models._generative_models import GenerativeModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gahco1OhtDGF"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth, drive\n",
        "import vertexai\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK7FFzpwtETM"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emns5wyntFhj"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfH8MwgptG3-"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"proud-archery-430400-i1\"\n",
        "LOCATION = \"us-west1\"\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSVJHUZTtIZv"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from vertexai.generative_models._generative_models import GenerativeModel\n",
        "\n",
        "class RocketLeagueGeminiGenerator:\n",
        "    def __init__(self):\n",
        "        self.MODEL_ID = \"gemini-1.5-pro-001\"\n",
        "        self.model = GenerativeModel(self.MODEL_ID)\n",
        "        self.BUDGET = 300\n",
        "        self.COST_PER_1K_CHARS = 0.00025\n",
        "        self.MAX_CHARS = int((self.BUDGET / self.COST_PER_1K_CHARS) * 1000)\n",
        "        self.EOS_TOKEN = \" EOS\"\n",
        "\n",
        "        self.story_starters = [\n",
        "            \"When encountering {scenario} in competitive 3v3, pro players recommend that\",\n",
        "            \"A common challenge in 3v3 matches is {scenario}. The best strategy here is to\",\n",
        "            \"During high-level gameplay, if {scenario} occurs, experienced players will\",\n",
        "            \"One critical situation in 3v3 is {scenario}. To handle this effectively, you should\",\n",
        "            \"Many players struggle with {scenario} in 3v3. The optimal approach is to\"\n",
        "        ]\n",
        "\n",
        "        self.generation_config = {\n",
        "            'candidate_count': 1,\n",
        "            'temperature': 0.7,\n",
        "            'top_p': 0.9,\n",
        "            'max_output_tokens': 1024,\n",
        "        }\n",
        "\n",
        "        self.stories_generated = 0\n",
        "        self.characters_generated = 0\n",
        "        self.last_aspect_index = 0\n",
        "\n",
        "        self.gameplay_scenarios = {\n",
        "            \"defensive_situations\": [\n",
        "                \"multiple opponents rushing the goal\",\n",
        "                \"defending against an air dribble setup\",\n",
        "                \"recovering from a defensive demo\",\n",
        "                \"low boost while last defender\",\n",
        "                \"protecting an empty net\"\n",
        "            ],\n",
        "            \"offensive_pressure\": [\n",
        "                \"maintaining ball control in the corner\",\n",
        "                \"executing a passing play\",\n",
        "                \"capitalizing on opponent's double commit\",\n",
        "                \"setting up a ceiling shot\",\n",
        "                \"creating demolition opportunities\"\n",
        "            ],\n",
        "            \"midfield_control\": [\n",
        "                \"challenging a 50/50 ball\",\n",
        "                \"managing boost-starved rotation\",\n",
        "                \"intercepting cross-field passes\",\n",
        "                \"supporting aggressive teammates\",\n",
        "                \"controlling midfield pressure\"\n",
        "            ],\n",
        "            \"critical_moments\": [\n",
        "                \"zero seconds remaining\",\n",
        "                \"overtime kickoff\",\n",
        "                \"one-goal lead defense\",\n",
        "                \"full-team rotation breakdown\",\n",
        "                \"boost-starved endgame\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.scenario_list = []\n",
        "        for category, scenarios in self.gameplay_scenarios.items():\n",
        "            for scenario in scenarios:\n",
        "                self.scenario_list.append((category, scenario))\n",
        "        random.shuffle(self.scenario_list)\n",
        "\n",
        "    def create_prompt(self, category: str, scenario: str, starter_template: str) -> str:\n",
        "        story_start = starter_template.format(scenario=scenario)\n",
        "\n",
        "        return f\"\"\"As a professional Rocket League 3v3 coach, provide specific tactical advice for the following scenario:\n",
        "\n",
        "{story_start}...\n",
        "\n",
        "Create a concise response (maximum 400 words) that continues the story starter above and covers:\n",
        "\n",
        "1. Primary Strategy\n",
        "- Immediate tactical response\n",
        "- Key mechanical execution\n",
        "- Positioning requirements\n",
        "\n",
        "2. Team Dynamics\n",
        "- Communication priorities\n",
        "- Role distribution\n",
        "- Support positioning\n",
        "\n",
        "3. Technical Details\n",
        "- Specific controls/inputs\n",
        "- Timing considerations\n",
        "- Mechanical sequences\n",
        "\n",
        "4. Risk Management\n",
        "- Common pitfalls\n",
        "- Backup options\n",
        "- Recovery plans\n",
        "\n",
        "Format the response to start exactly with:\n",
        "\"{story_start}...\"\n",
        "\n",
        "Keep the advice practical and focused on high-level competitive play. Include specific mechanical inputs where relevant.\"\"\"\n",
        "\n",
        "    def generate_story(self) -> tuple[str, int, str, str]:\n",
        "        category, scenario = self.scenario_list[self.last_aspect_index % len(self.scenario_list)]\n",
        "        starter_template = self.story_starters[self.stories_generated % len(self.story_starters)]\n",
        "        prompt = self.create_prompt(category, scenario, starter_template)\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                [{'role': 'user', 'parts': [{'text': prompt}]}],\n",
        "                generation_config=self.generation_config\n",
        "            )\n",
        "            story = response.text.strip() + self.EOS_TOKEN\n",
        "            chars = len(story)\n",
        "            return story, chars, category, scenario\n",
        "        except Exception as e:\n",
        "            print(f\"Gemini API error: {e}\")\n",
        "            return \"\", 0, category, scenario\n",
        "\n",
        "    def save_progress_state(self, output_dir: str):\n",
        "        state = {\n",
        "            \"stories_generated\": self.stories_generated,\n",
        "            \"characters_generated\": self.characters_generated,\n",
        "            \"last_aspect_index\": self.last_aspect_index,\n",
        "            \"budget_used\": (self.characters_generated / 1000) * self.COST_PER_1K_CHARS,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "\n",
        "        state_file = os.path.join(output_dir, \"generation_state.json\")\n",
        "        with open(state_file, 'w') as f:\n",
        "            json.dump(state, f, indent=4)\n",
        "\n",
        "        print(f\"Progress state saved to {state_file}\")\n",
        "\n",
        "    def load_progress_state(self, output_dir: str) -> Dict:\n",
        "        state_file = os.path.join(output_dir, \"generation_state.json\")\n",
        "        try:\n",
        "            with open(state_file, 'r') as f:\n",
        "                state = json.load(f)\n",
        "                self.stories_generated = state[\"stories_generated\"]\n",
        "                self.characters_generated = state[\"characters_generated\"]\n",
        "                self.last_aspect_index = state[\"last_aspect_index\"]\n",
        "                print(f\"Loaded previous state from {state_file}\")\n",
        "                print(f\"Last run statistics:\")\n",
        "                print(f\"- Stories generated: {self.stories_generated}\")\n",
        "                print(f\"- Characters generated: {self.characters_generated:,}\")\n",
        "                print(f\"- Budget used: ${state['budget_used']:.2f}\")\n",
        "                print(f\"- Last timestamp: {state['timestamp']}\")\n",
        "                return state\n",
        "        except FileNotFoundError:\n",
        "            print(\"No previous state found, starting fresh\")\n",
        "            return {}\n",
        "\n",
        "    def save_stories(self, stories: List[str], output_dir: str):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        stories_file = os.path.join(output_dir, \"stories.txt\")\n",
        "        with open(stories_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"\\n\\n---\\n\\n\".join(stories))\n",
        "\n",
        "        backup_file = os.path.join(output_dir, f\"stories_backup_{int(time.time())}.txt\")\n",
        "        with open(backup_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"\\n\\n---\\n\\n\".join(stories))\n",
        "\n",
        "        self.save_progress_state(output_dir)\n",
        "\n",
        "        print(f\"\\nProgress saved:\")\n",
        "        print(f\"- Main file: {stories_file}\")\n",
        "        print(f\"- Backup file: {backup_file}\")\n",
        "        print(f\"- Stories: {len(stories)}\")\n",
        "        print(f\"- Budget used: ${(self.characters_generated / 1000) * self.COST_PER_1K_CHARS:.2f} of ${self.BUDGET}\")\n",
        "        print(f\"- Characters remaining: {self.MAX_CHARS - self.characters_generated:,}\")\n",
        "\n",
        "    def load_existing_stories(self, output_dir: str) -> List[str]:\n",
        "        stories_file = os.path.join(output_dir, \"stories.txt\")\n",
        "        try:\n",
        "            with open(stories_file, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "                if content:\n",
        "                    stories = content.split(\"\\n\\n---\\n\\n\")\n",
        "                    return stories\n",
        "        except FileNotFoundError:\n",
        "            return []\n",
        "        return []\n",
        "\n",
        "    def generate_dataset(self, output_dir: str):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        self.load_progress_state(output_dir)\n",
        "        stories = self.load_existing_stories(output_dir)\n",
        "\n",
        "        print(f\"\\nGenerating stories within ${self.BUDGET} budget...\")\n",
        "        print(f\"Maximum characters allowed: {self.MAX_CHARS:,}\")\n",
        "        print(f\"Starting from story #{len(stories) + 1}\")\n",
        "\n",
        "        try:\n",
        "            while self.characters_generated < self.MAX_CHARS:\n",
        "                print(f\"\\nGenerating story #{len(stories) + 1}\")\n",
        "                print(f\"Using story starter #{(self.stories_generated % len(self.story_starters)) + 1}\")\n",
        "\n",
        "                story, chars, category, scenario = self.generate_story()\n",
        "                print(f\"Category: {category}\")\n",
        "                print(f\"Scenario: {scenario}\")\n",
        "\n",
        "                if story:\n",
        "                    if self.characters_generated + chars > self.MAX_CHARS:\n",
        "                        print(\"Would exceed budget. Stopping generation.\")\n",
        "                        break\n",
        "\n",
        "                    preview = story[:150] + \"...\" if len(story) > 150 else story\n",
        "                    print(f\"\\nNew story preview: {preview}\")\n",
        "                    print(f\"Characters in this story: {chars}\")\n",
        "\n",
        "                    stories.append(story)\n",
        "                    self.characters_generated += chars\n",
        "                    self.stories_generated += 1\n",
        "                    self.last_aspect_index += 1\n",
        "\n",
        "                    if self.stories_generated % 5 == 0:\n",
        "                        print(f\"\\nSaving checkpoint at {self.stories_generated} stories...\")\n",
        "                        self.save_stories(stories, output_dir)\n",
        "\n",
        "                time.sleep(2)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nGeneration interrupted by user. Saving progress...\")\n",
        "            self.save_stories(stories, output_dir)\n",
        "        except Exception as e:\n",
        "            print(f\"\\nUnexpected error: {str(e)}\")\n",
        "            print(\"Saving current progress...\")\n",
        "            self.save_stories(stories, output_dir)\n",
        "            raise\n",
        "\n",
        "        self.save_stories(stories, output_dir)\n",
        "\n",
        "        print(f\"\\nFinal Statistics:\")\n",
        "        print(f\"Stories generated: {self.stories_generated}\")\n",
        "        print(f\"Total characters: {self.characters_generated:,}\")\n",
        "        print(f\"Final cost: ${(self.characters_generated / 1000) * self.COST_PER_1K_CHARS:.2f}\")\n",
        "        print(f\"Average chars/story: {self.characters_generated / self.stories_generated if self.stories_generated > 0 else 0:.2f}\")\n",
        "\n",
        "def main():\n",
        "    generator = RocketLeagueGeminiGenerator()\n",
        "    output_dir = \"rocket_league_output_v2\"\n",
        "    generator.generate_dataset(output_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
